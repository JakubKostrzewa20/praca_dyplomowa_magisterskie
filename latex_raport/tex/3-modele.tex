\newpage % Rozdziały zaczynamy od nowej strony.
\section{Modele}
W poniższym rozdziale przedstawiono rodziny modeli głębokiego uczenia, które zostaną wykorzystane w pracy dyplomowej w ramach badania ich możliwości na wybranym wcześniej zbiorze danych zawierającym rośliny uprawe i choroby. Trzy z tych modeli reprezentują klasyczne podejście w postaci architektury CNN – ResNet, MobileNet oraz EfficientNet oraz jeden model bedący podstawową implementacją transformera wizyjnego – ViT. Wybór został podyktowany próbą rozwinięcia wcześniej dokonanych badań przedstawionych w przeglądzie literatury. Wybór szeroko używanych modeli CNN oraz nowego, mniej popularnego modelu architektury ViT pozwoli na porównanie nie tylko wydajności samych modeli, ale może dostarczyć ciekawych wniosków dotyczących typów architektur oraz ich skuteczności. Każdy z poniższych podrozdziałów przedstawia każdy z wybranych modeli oraz krótko opisuję zasadę ich działania, która odróżnia go od innych.   
\subsection{MobileNet}
MobileNet to rodzina modeli konwolucyjnych sieci neuronowych(CNN). Stworzona przez firmę Google,  zaprojektowana została z myślą o wykonywaniu zadań z dziedziny wizji komputerowej - klasyfikacja obrazów, detekcja obiektów itp. Są to małe modele o niskiej liczbie parametrów i małych opóźnieniach, zaprojektowane z myślą o ograniczeniach zasobów obliczeniowych, spotykanych w wielu sprzętach elektronicznych, głównie telefonach mobilnych. Charakterystyczną cechą tego modelu jest zastosowanie splotów separowanych głębinowo. Jest to połączenie splotu głębinowego, który polega na wykonywaniu splotu niezależnie dla każdego kanału mapy cech, co oznacza, że każdy kanał posiada swoje własne jądro, oraz splotu punktowego, który służy do łączenia cech i zmiany wymiaru.\cite{howard2017mobilenets}
\subsection{ViT}
ViT to rodzina modeli stworzonych przez Google, ale też architektura sieci neuronowej, inna od CNN, nazywana transformerem wizyjnym. Modele stworzone od Google, są podstawową implementacją tej architektury, gdzie każdy  model z rodziny ma z góry narzucone inne parametry.\cite{dosovitskiy2020image}
\subsection{ResNet}
ResNet to rodzina modeli konwolucyjnych sieci neuronowych (CNN), stworzona przez firmę Microsoft,  implementujących koncept nauczania rezydualnego. Rozwiązuje to problem zanikającego/eksplodującego gradientu i umożliwia trenowanie bardzo głębokich sieci neuronowych. W sieci tej użyta jest technika zwana połączeniem skrótowym. Połączenie to łączy aktywacje warstwy do kolejnych warstw, pomijając część warstw. Tworzy to strukturę nazwaną blokiem rezydualnym. Pozwala to sieci na naukę różnicy między wyjściem a wejściem bloku, zamiast dokonywać aproksymacji docelowej funkcji. \cite{he2016deep}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{img/res_net.png}
	\caption{	Przedstawienie budowy oraz działania bloku rezydualnego.\cite{he2016deep}}
	\label{fig:res_net_rys}
\end{figure}

\subsection{EfficentNet}
EfficientNet to rodzina modeli konwolucyjnych sieci neuronowych(CNN) stworzonych przez Google. Naukowcy stojący za stworzeniem tego modelu, zauważyli, że różne wymiary skalowania nie są od siebie niezależne. Dla przykładu, dla obrazów o wyższej rozdzielczości, zwiększenie głębokości sieci pomaga polom recepcyjnym w uchwyceniu podobnych cech. Analogicznie, powinno się również zwiększyć szerokość sieci, aby umożliwić znajdywanie bardziej złożonych wzorców w obrazach o większej rozdzielczości. Doprowadziło to autorów do opracowania skalowania złożonego, czyli jednorodnego skalowania szerokości, głębokości oraz rozdzielczości sieci. Pozwoliło to na uzyskanie modelu, który osiąga wyniki lepsze niż inne modele dostępne na rynku w trakcie pierwotnego badania.\cite{tan2019efficientnet} 
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{img/efficientnet.png}
	\caption{Przykładowa macierz pomyłek dla trzech klas, z wynikami otzymywanymi dla klasy ‘B’.}
	\label{fig:macierz_konfliktu}
\end{figure}

